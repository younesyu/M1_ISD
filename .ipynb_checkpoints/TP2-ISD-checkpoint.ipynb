{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9k8hIyfX4Qij"
   },
   "source": [
    "# Introduction à la Science de Données\n",
    "# TP2 -  Classification par les $k$ plus proches voisins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lTccv7A74Qin"
   },
   "source": [
    "La documentation Scikit-learn sur les $k$ plus proches voisins se trouve ici: http://scikit-learn.org/stable/modules/neighbors.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_oWf2JPjfcbX"
   },
   "source": [
    "## Données *digits*\n",
    "Dans la première partie de ce TP, nous allons utiliser des données déjà présentes dans scikit-learn, à l'image des données Iris du premier TP.\n",
    "\n",
    "Ces données sont très connues en apprentissage, sous le noms de MNIST. Elles sont composées d'images de chiffres manuscrits à une résolution de 8*8. En scikit-learn, elles se nomment digits : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdPIwHd0gNA-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.py:9: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/feature_extraction/hashing.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from . import _hashing\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py:24: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py:26: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from .sparsefuncs_fast import csr_row_norms\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._random import sample_without_replacement\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/datasets/svmlight_format.py:25: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._svmlight_format import _load_svmlight_file\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # importation du package numérique\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digitsData=load_digits() # jeu de données digits\n",
    "X=digitsData.data # les exemples, un array numpy, chaque élément est aussi un array\n",
    "y=digitsData.target # les classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7sIgf8FP9UMj"
   },
   "source": [
    "On peut regarder quelques informations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PJ_o58ap9dBH",
    "outputId": "cecb6676-24cb-4659-f8b1-decb460f5764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(dtype('float64'), (1797, 64))\n",
      "(dtype('int64'), (1797,))\n"
     ]
    }
   ],
   "source": [
    "print(X.dtype, X.shape)\n",
    "print(y.dtype, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPTbrn1niFXe"
   },
   "source": [
    "Chaque donnée est donc une image de 8 pixels par 8 pixels, en niveau de gris (256 nuances possibles), stockée sous la forme d'un vecteur de dimension 64 comme une ligne de la matrice $X$ (il y a 1797 images) et avec la valeur de la classe associée stockée dans un vecteur $y$ à part (comme pour Iris). Mais on peut quand même regarder l'image initiale :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "TDLOkUoZinAj",
    "outputId": "afeff7a5-2f1c-47b9-c6ac-bae4317e7824"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # le package de visualisation\n",
    "# la ligne spéciale pour que le notebook affiche comme il faut :\n",
    "%matplotlib inline  \n",
    "\n",
    "donnee = X[42,:] # on récupère une ligne, donc une donnée\n",
    "classe = y[42]   # et sa classe\n",
    "print(\"Le vecteur de l'image d'indice 42 : \", donnee)\n",
    "\n",
    "image = np.reshape(donnee,(8,8)) # on met les 8 morceaux de taille 8 du vecteur les uns en dessous des autres\n",
    "print(image) # on affiche la matrice de pixels\n",
    "plt.imshow(image) # on affiche l'image qui lui correspond\n",
    "plt.title('Donnee numero 42, de la classe %i \\n' % classe, fontsize = 16) # avec un titre\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GvoCa-lMppar"
   },
   "source": [
    "On peut faire des affichages plus intéressant, exemple sur les 5 premières données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "23nNOIYy7h1K",
    "outputId": "986f6bba-aa2f-4b7e-d496-3ff34f284feb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "for index, (image, classe) in enumerate(zip(X[0:5], y[0:5])): # \n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title('Classe : %i\\n' % classe, fontsize = 18)\n",
    "plt.show()\n",
    "    \n",
    "plt.figure(figsize=(16,4))\n",
    "for index, (image, classe) in enumerate(zip(X[42:47], y[42:47])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=\"copper\")\n",
    "    plt.title('Classe : %i\\n' % classe, fontsize = 18)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ci58h2vz4Qiq"
   },
   "source": [
    "## Création et entraînement d'un classifieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efNARzTG4Qiv"
   },
   "source": [
    "Notre objectif est maintenant d'apprendre, sur la base d'un échantillon d'images \"chiffres\", un classifieur capable de prédire le chiffre qui correspond à une nouvelle image. Nous allons utiliser la méthode des $k$-plus proches voisins pour cet apprentissage. Elle est implémentée dans un package appelé *neighbors*. Examinons la série d'instructions suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5646
    },
    "colab_type": "code",
    "id": "NyjLe8Ai4Qiy",
    "outputId": "7480e968-21fe-4401-d027-dc7cd9fbe9b1"
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors as nn # importation du package d'algorithmes travaillant sur les points voisins\n",
    "help(nn.KNeighborsClassifier) # que fait cette instruction qui sera très utile par la suite?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHnrWhos4Qi9"
   },
   "source": [
    "Sympa, non ? Ce type d'instruction est utilisable pour toute classe de Python. \n",
    "\n",
    "Continuons l'exploration des $k$ plus proches voisins. Dans la série d'instructions suivante, on indique comment un classifieur peut être appris à partir de données étiquetées, et comment réaliser la prédiction sur un nouvel exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OOZ0WxXZ4QjO"
   },
   "source": [
    "Les fonctions *predict* et *fit* existent **pour tous les classifieurs** disponibles dans scikit-learn.\n",
    "\n",
    "On note ici la syntaxe de la fonction *predict* : on lui passe en réalité un tableau d'exemples (ici, un tableau avec un seul exemple constitué de 64 attributs), et elle renvoit un tableau contenant la classe prédite pour chaque exemple du tableau en paramètre. Evidemment, dans les tableaux en entrée et en sortie, les indices des classes prédites correspondent aux indices des exemples en entrée ! \n",
    "\n",
    "Ainsi, lorsque l'on sait que l'on n'applique predict qu'à un seul exemple, une sélection finale [0] comme ci-après renvoit la première (et la seule) composante du tableau de résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "abQTK7Mm4QjH",
    "outputId": "04aa51cc-e3ca-42d9-ffc8-a9b1d632294b"
   },
   "outputs": [],
   "source": [
    "nb_voisins = 15 # on fixe le nombre de voisins, à partir de 2 et au max le nombre d'exemples dans le jeu de données\n",
    "clf = nn.KNeighborsClassifier(nb_voisins) \n",
    "# ci-dessus, création d'un classifieur: la variable clf est un \"objet\" classifieur, vide pour l'instant \n",
    "#print(clf) # le classifieur est vide pour l'instant, il n'a pas été entraîné sur des données\n",
    "clf.fit(X, y) # entraînement du classifieur clf sur les données étiquetées\n",
    "nouvel_ex = np.random.randint(0,256,64,int)\n",
    "print('prédiction pour le nouvel exemple: ',\n",
    "      clf.predict(nouvel_ex.reshape(1,-1))) # prédiction du modèle appris sur la description d'un chiffre aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9zal_50w4QjR",
    "outputId": "7e81f630-fbf9-4217-b3dc-c9ec48b52f5c"
   },
   "outputs": [],
   "source": [
    "print('prédiction pour le nouvel exemple: ', clf.predict(nouvel_ex.reshape(1,-1))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FymLN7OV4Qja"
   },
   "source": [
    "Pour certains types de classifieurs, on peut même récupérer la probabilité que le classifieur attribue à l'appartenance de l'exemple à chaque classe possible. La fonction *predict_proba* fonctionne comme la fonction *predict*, sauf que le tableau en sortie contient, pour chaque exemple du tableau en entrée, un tableau de probabilité de la même taille que le nombre de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "Lnzq5Zut4Qjf",
    "outputId": "e6e6ff86-aa08-4476-9276-5ff4f7b93e73",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autre_ex=np.random.randint(0,256,64,int) # on génère un autre exemple aléatoirement, avec 64 attributs prenant leurs valeurs entre 0 et 255\n",
    "print(clf.predict_proba(nouvel_ex.reshape(1,-1))[0]) # probabilité d'appartenance à chaque classe pour ce chiffre\n",
    "print(clf.predict_proba(autre_ex.reshape(1,-1))[0]) # idem pour un autre exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJgdW_NF4Qjn"
   },
   "source": [
    "Ci-dessus, le premier nouvel exemple est classé dans la classe d'indice 7, pour laquelle la probabilité est la plus grande.\n",
    "\n",
    "A votre avis, quelle classe sera attribuée au deuxième exemple, et pourquoi ? Indiquez ci-après l'instruction à exécuter pour vérifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwmb39cy4Qjs"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsSaiAzO4Qj9"
   },
   "source": [
    "Une première façon d'évaluer la qualité d'un classifieur est de le tester sur les exemples qui ont servi à l'apprendre. On utilise du coup la même fonction *predict*, appliquée au tableau des exemples d'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "at1QD73r4Qj_",
    "outputId": "e839e11c-e7a3-4702-a4d9-2706d4faa035"
   },
   "outputs": [],
   "source": [
    "Z = clf.predict(X) # vecteur des classes prédites pour chaque exemple de l'ensemble d'apprentissage\n",
    "print(X[Z!=y]) # le tableau d'exemples pour lesquels la prédiction a été mauvaise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkfXE6dx4QkF"
   },
   "source": [
    "Indiquez ci-après les instructions qui permettent (1) de connaître les probabilités d'appartenance des exemples mal classés à chacune des 10 classes de *digit*, et (2) les vraies classes de ces exemples (pour cela, on peut utiliser la fonction *numpy.argwhere* avec un peu de jugeotte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZATD9txd4QkJ"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7n9FWWs4QkV"
   },
   "source": [
    "Chaque classifieur possède une fonction *score*, qui permet de comparer les prédictions d'un ensemble d'exemples $X$ pour lesquelles on connaît les étiquettes $y$ : la fonction calcule le taux de bonne classifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UJsi-fuG4QkY",
    "outputId": "a2c20e7f-8881-4e12-ac8d-f40fa08f7966"
   },
   "outputs": [],
   "source": [
    "print('taux de bonne classification', clf.score(X,y)) # taux de bonne classification du modèle sur l'ensemble d'apprentissage: fonction score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2I8C2sn4Qkd"
   },
   "source": [
    "On la détourne facilement pour obtenir le taux d'erreur : faites le (vous devez obtenir 0.01446855...)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3kjUGxv4Qki"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ag7_Jwgr4Qk6"
   },
   "source": [
    "## Variation du nombre de voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0GE1r3Yq4Qk7"
   },
   "source": [
    "L'algorithme des $k$-plus proches voisins fonctionne avec plusieurs hyper-paramètres (paramètres de l'agorithme, pas du modèle appris): la valeur de $k$ est un de ces paramètres. Réalisez un programme qui fait varier cet hyper-paramètres dans un intervalle comprenant des valeurs entre 2 et 15, et stocker l'évolution de l'erreur d'apprentissage (celle calculée sur l'échantillon d'apprentissage), puis en réaliser une courbe avec en abscisse les valeurs de k, et en ordonnées les erreurs.\n",
    "\n",
    "On peut utiliser pour ce faire la fonction de construction d'un tableau *numpy.arange* (cf documentation), la fonction *len(X)* qui renvoit la taille d'un tableau à une dimension. Pour la courbe, on utilisera simplement *plot(abs, ord)* du package *pyplot* de *matplotlib*, comme vue au premier TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RK49MqBj4Qk9"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FKPvlY14QlQ"
   },
   "source": [
    "Qu'observez-vous ? A quelle valeur de k atteint-on un meilleur classifieur ? Quelle est globalement, sur ce jeu de données, l'influence de $k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6bMmcGP4QlR"
   },
   "source": [
    "## Evaluation de l'erreur réelle du classifieur appris "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8h8dMnM4QlT"
   },
   "source": [
    "Lorsque le score du classifieur appris est évalué sur l'ensemble d'apprentissage, il est en général sur-estimé (pourquoi ?) et donc, très peu fiable. La meilleure méthode pour évaluer un classifieur consiste à calculer son score sur un échantillon test, indépendant de l'échantillon d'apprentissage mais généré dans les mêmes\n",
    "conditions. Lorsqu'on dispose d'un seul ensemble d'exemples (comme c'est le cas de *digits*, il faut donc:\n",
    "\n",
    "* répartir les données en un sous-ensemble d'apprentissage et un sous-ensemble test,\n",
    "* entrainer un classifieur sur l'ensemble d'apprentissage \n",
    "* évaluer ce classifieur sur l'ensemble test (on a ici une évaluation de l'erreur réelle, qui reste instable puisque dépend du découpage effectué)\n",
    "\n",
    "Si les données sont peu nombreuses, comme c'est le cas pour le jeu de données *digits*, cette évaluation risque d'être pessimiste (avez-vous une idée de pourquoi ? Si oui, expliquez, sinon réfléchissez!).\n",
    "\n",
    "Scikit-learn vient avec toute une panoplie d'outils pour évaluer cette erreur. Pour l'instant, nous n'utiliserons que la fonction qui permet de diviser un échantillon en deux parties (attributs et classes): c'est la fonction *train_test_split* du package *model_selection*, que nous appliquons ci-après sur Iris (nous ne printons que les trois premiers exemples de chaque sous-échantillon, avec leurs étiquettes):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "n_FJ2xiw4QlT",
    "outputId": "ba0e0283-25f5-4349-a469-665c3a5738c3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# production de deux sous-échantillon\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.25, random_state=42) \n",
    "\n",
    "print(Xtrain[:3,:], ytrain[:3])\n",
    "print(Xtest[:3,:], ytest[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56FteqCq4QlZ"
   },
   "source": [
    "Ici, nous produisons un découpage dans lequel l'ensemble d'apprentissage représente 60% de l'échantillon initial, et l'échantillon de test reprend 40% des données initiales.\n",
    "\n",
    "En vous inspirant de ce mode de découpage, écrire une séquence d'instructions permettant de séparer *digits* en deux parties égales, d'apprendre un 3-plus proches voisins sur le premier sous-échantillon, et de le tester sur le second: vous obtenez une **estimation** de l'erreur réelle. Obtenez-vous la même erreur que celle d'apprentissage mesurée précédemment ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8kQdGIU4QlZ"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6f608IhM4Qlo"
   },
   "source": [
    "Faites maintenant à nouveau varier $k$, et pour chaque valeur, indiquez l'erreur réelle estimée sur la base d'un train_test_split de 70%, 30% ; tracer la courbe. Observez-bien les différences de valeurs des erreurs d'apprentissage et réelle: pourquoi sont-elles différentes ? Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4T5bH6HG4Qlp"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtuiGNxH4Ql8"
   },
   "source": [
    "## Variation autour de la métrique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpHiq-m24Ql9"
   },
   "source": [
    "Au delà du nombre de voisins, un autre hyper-paramètre est la métrique utilisée pour calculer la distance entre les exemples. Par défaut, la distance de Minkowski est utilisée, avec le paramètre $p=2$ qui indique que nous considérons la distance euclidienne. Avec $p=1$, nous aurions la distance de manhattan, et de façon générale, avec p>0, la distance utilisée est $l_p$ :\n",
    "\n",
    "$$l_p(x, x')=(\\sum_{i=1}^n |x_i - x'_i|^p)^{\\frac{1}{p}}$$\n",
    "\n",
    "Ecrire un programme permettant de faire varier la distance utilisée pour évaluer son impact sur les performances, en faisant aussi varier $k$. Tracez les 3 courbes sur un même plot (cf. doc de *plot* pour voir comment faire), une pour chaque valeur de $p$ parmi ${1,2,5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtpJAvCs4QmA"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpZryjjk4QmI"
   },
   "source": [
    "# Analyse en composantes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bl-sB9fd4QmJ"
   },
   "source": [
    "## Un exemple sur Iris "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1lCUg4w4QmK"
   },
   "source": [
    "l'ACP est une méthode classique des statistiques qui consiste à transformer des variables liées entre elles en nouvelles variables décorrélées les unes des autres. \n",
    "Ces nouvelles variables sont les composantes principales. L'ACP permet de réduire le nombre de variables décrivant le problème et de rendre l'information moins redondante.\n",
    "\n",
    "En apprentissage automatique, l'ACP est parfois naturellement utilisée en pré-traitement des données, notamment pour réduire les dimensions, les décorréler ou les débruiter.\n",
    "Nous illustrons ici l'ACP à des fins de visualisation des données~: nous ne gardons que les deux composantes principales.\n",
    "\n",
    "L'ACP est disponile sous sklearn dans le package decomposition. L'exemple ci-dessous illustre l'application d'une ACP au jeu de données *Iris*, et sa visualisation. Comme évoqué en cours, l'ACP réalise une centralisation (et parfois une réduction) des données d'entrée, lors du calcul des composantes principaux. Il est important de comprendre cette petite astuce pour pouvoir être capable de faire cette projection manuellement si besoin. Le mode de fonctionnement de cette projection après centralisation est illustré au milieu du programme.\n",
    "\n",
    "A la fin, un mode d'affichage des données transformées est proposé.\n",
    "\n",
    "Comprendre ce programme et l'exécuter. La séparation des classes vous semble-t-elle plus facile dans l'espace des composantes principales ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "colab_type": "code",
    "id": "N5Cs1DoY4QmK",
    "outputId": "abd386db-6cc2-4868-ebe9-3b92e9dec6a8"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "FIG_SIZE = (20, 14)\n",
    "COLORS = ['blue', 'red', 'green']\n",
    "SYMBOLS = ['^', 's', '+']\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "\n",
    "# Transformation des données par ACP\n",
    "pca = PCA(n_components=2) # creation d'un objet acp, on ne garde que les deux premières composantes principales\n",
    "pca.fit(X) # calcul des composantes principales\n",
    "\n",
    "# extraire les composantes principales, puis afficher le dataset selon elles\n",
    "X_pca = pca.transform(X) # projection des données sur le nouvel espace 2D\n",
    "\n",
    "#################### Illustration de la nécessaire centralisation des données pour la PCA\n",
    "print('\\nPremiere CP1 = ', pca.components_[0]) # obtention de la PCA1 par transformation des variables initiales\n",
    "print('Seconde CP2 = ', pca.components_[1])\n",
    "print('Moyennes des variables selon ACP = ',pca.mean_)\n",
    "print('Moyenne de la premiere variable dans echantillon = ',np.mean(X[:,0]))\n",
    "print('Premier point IRIS ', X[0])\n",
    "pointrecentre = X[0]-pca.mean_\n",
    "print('Premier point IRIS recentre = ', pointrecentre )\n",
    "# verification du point transforme: on fait le calcul à la main\n",
    "point = np.dot(pointrecentre, np.transpose(pca.components_)) # mode de calcul du premier individu\n",
    "print('Transformation manuelle = ', point)\n",
    "print('Transformation acp = ', X_pca[0])  \n",
    "####################################################################\n",
    "\n",
    "# Visualisation des points projetés dans l'espace des deux premières composantes principales\n",
    "for l, c, m in zip(range(0, 3), COLORS, SYMBOLS):\n",
    "    plt.scatter(X_pca[y == l, 0], X_pca[y == l, 1],\n",
    "                color=c,\n",
    "                label='class %s' % l,\n",
    "                alpha=0.5,\n",
    "                marker=m\n",
    "                )\n",
    "plt.xlabel('premiere composante principale')\n",
    "plt.ylabel('deuxieme composante principale')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJuPu60m4QmQ"
   },
   "source": [
    "Inspirez vous de ce programme pour appliquer l'ACP au jeu de données *digits*. Ensuite, (1) produire la figure de visualisation des données projetées, et (2) utiliser ces données projetées pour apprendre un $k$-ppv avec la norme $l2$, et tester ses performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEKdUyeHejeG"
   },
   "outputs": [],
   "source": [
    "# A vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "id2FVb3f6zfc"
   },
   "source": [
    "# Retour sur la matrice de covariance : standardisation nécessaire\n",
    "\n",
    "Nous avons déjà visualisé les données du jeu * Iris* en 2D, en visualisant dans de multiples graphiques la co-variation de chaque couple de variables (attributs). Rappelons maintenant que la matrice de covariance peut être un indicateur de ces co-variations, sans visualisation.\n",
    "\n",
    "Voici une façon simple de calculer la matrice de covariance de Iris. Comprenez les instructions au regard du cours, et visualisez le résultat après exécution des instructions. Quelles sont les variables qui co-varient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "Pi-mS5AT68sl",
    "outputId": "a9801ff1-6d59-4dae-9a82-95511b1a22a3"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "C = np.dot(np.transpose(X), X)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2PBZoMY7ipA"
   },
   "source": [
    "Analysez attentivement cette matrice de covariance: quel est le couple de variables qui co-varient le plus ? \n",
    "\n",
    "Nous allons calculer cette même matrice après avoir standardisé les données pour les ramener à une variance unitaire: la standardisation est un processus classique qui permet de ramener tous les points autour de l'origine, de telle sorte que la variance globale de chaque variable soit unitaire. Pour chaque variable, $x$, et pour chaque ligne $i$, on standardise $x_i$ ainsi:\n",
    "$$x_i^s = \\frac{(x_i-\\bar{x})}{\\sigma(x)}$$\n",
    "\n",
    "Voici une façon de faire cette standardisation facilement avec sklearn: on utilise un opérateur qui va calculer dans un premier temps moyennes et écarts-types de chaque variable de l'échantillon, puis qui pourra alors transformer les données en conséquences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "dUKSTyk-9Lnl",
    "outputId": "b240f46e-e680-4bcc-b03c-946f455d4825"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "print(X[0:2,:]) # affichage des deux premiers exemples \"bruts\"\n",
    "scaler = StandardScaler() # le scaleur\n",
    "scaler.fit(X) # calcul des statistiques élémentaires\n",
    "Xstd = scaler.transform(X) # calcul de la standardisation de chaque donnée\n",
    "print(Xstd[0:2,:]) # affichage des deux premiers exemples standardisés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGoULy1wyTA8"
   },
   "source": [
    "Calculez maintenant la matrice de covariance de notre échantillon, après cette standardisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nN4tuuhxykry"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DKdJ3sp3yvy9"
   },
   "source": [
    "Quelles sont les deux variables qui co-varient le plus ? Est-ce que ce sont les mêmes que sans la normalisation préalable ?\n",
    "\n",
    "Dans le cas du jeu de données Iris, on constate que la standardisation change la donne. Dans certains jeux de données, le changement est spectaculaire.\n",
    "\n",
    "Appliquons maintenant ce même exercice aux jeu de données sur les vins, qui comporte 13 attributs d'échelle différentes: à partir de ce jeu de données (que l'on charge avec load_wine du package sklearn.datasets), \n",
    "indiquez les instructions permettant de calculer la matrice de covariance avant et après normalisation, puis déterminez dans chaque cas quel est le couple d'attributs qui varient le plus ensemble.\n",
    "\n",
    "1.  indiquez les instructions permettant de calculer la matrice de covariance avant et après normalisation, puis déterminez dans chaque cas quel est le couple d'attributs qui varient le plus ensemble.\n",
    "2.  comparez les performances d'un $k$-ppv sur les données transformées par ACP (réduction à deux dimensions), avec et sans standardisation ; dans quel cas l'estimation de l'erreur en généralisation est-elle meilleure ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4v2X23L2N_8"
   },
   "outputs": [],
   "source": [
    "# a vous"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tp2-M1ISD.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
